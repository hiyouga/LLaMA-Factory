{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a0e469-cf89-4198-a8ab-f0ddee126da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'LLaMA-Factory/'\n",
      "/workspace/LLaMA-Factory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd LLaMA-Factory/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f72595-f9de-4b0c-88cb-1cdf3d2d5b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers<=4.46.1,>=4.41.2 (from -r requirements.txt (line 1))\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets<=3.1.0,>=2.16.0 (from -r requirements.txt (line 2))\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting accelerate<=1.0.1,>=0.34.0 (from -r requirements.txt (line 3))\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft<=0.12.0,>=0.11.1 (from -r requirements.txt (line 4))\n",
      "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting trl<=0.9.6,>=0.8.6 (from -r requirements.txt (line 5))\n",
      "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tokenizers<0.20.4,>=0.19.0 (from -r requirements.txt (line 6))\n",
      "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting gradio<5.0.0,>=4.0.0 (from -r requirements.txt (line 7))\n",
      "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pandas>=2.0.0 (from -r requirements.txt (line 8))\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy (from -r requirements.txt (line 9))\n",
      "  Downloading scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting einops (from -r requirements.txt (line 10))\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sentencepiece (from -r requirements.txt (line 11))\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tiktoken (from -r requirements.txt (line 12))\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting protobuf (from -r requirements.txt (line 13))\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting uvicorn (from -r requirements.txt (line 14))\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pydantic (from -r requirements.txt (line 15))\n",
      "  Downloading pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting fastapi (from -r requirements.txt (line 16))\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting sse-starlette (from -r requirements.txt (line 17))\n",
      "  Downloading sse_starlette-2.2.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting matplotlib>=3.7.0 (from -r requirements.txt (line 18))\n",
      "  Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting fire (from -r requirements.txt (line 19))\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (23.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (6.0.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (1.24.1)\n",
      "Collecting av (from -r requirements.txt (line 23))\n",
      "  Downloading av-14.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting tyro<0.9.0 (from -r requirements.txt (line 24))\n",
      "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1))\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1))\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1))\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1))\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0 (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1))\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (2023.4.0)\n",
      "Collecting aiohttp (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (2.1.0+cu118)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7)) (4.0.0)\n",
      "Collecting ffmpy (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7)) (2.1.2)\n",
      "Collecting orjson~=3.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading orjson-3.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7)) (9.3.0)\n",
      "Collecting pydub (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading ruff-0.9.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7)) (4.4.0)\n",
      "Collecting urllib3~=2.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 8)) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas>=2.0.0->-r requirements.txt (line 8))\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=2.0.0->-r requirements.txt (line 8))\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting click>=7.0 (from uvicorn->-r requirements.txt (line 14))\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting h11>=0.8 (from uvicorn->-r requirements.txt (line 14))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->-r requirements.txt (line 15))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic->-r requirements.txt (line 15))\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions~=4.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi->-r requirements.txt (line 16))\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.7.0->-r requirements.txt (line 18))\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.7.0->-r requirements.txt (line 18))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.7.0->-r requirements.txt (line 18))\n",
      "  Downloading fonttools-4.55.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=3.7.0->-r requirements.txt (line 18))\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (2.4.7)\n",
      "Collecting termcolor (from fire->-r requirements.txt (line 19))\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting docstring-parser>=0.16 (from tyro<0.9.0->-r requirements.txt (line 24))\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1.0 (from tyro<0.9.0->-r requirements.txt (line 24))\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro<0.9.0->-r requirements.txt (line 24))\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7)) (1.1.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7)) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7)) (1.3.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7)) (2022.12.7)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1))\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading huggingface_hub-0.24.4-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting fsspec[http]<=2024.9.0,>=2023.1.0 (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (2.1.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 24))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 24)) (2.16.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (3.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (2.1.0)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 7))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 24))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (1.3.0)\n",
      "Downloading transformers-4.46.1-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m150.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m161.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m140.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sse_starlette-2.2.1-py3-none-any.whl (10 kB)\n",
      "Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading av-14.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading fonttools-4.55.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m174.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m162.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.4/130.4 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.9.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114248 sha256=ae6dac19f6b197ca370214e60c00fa2cce0dfab940a6393d9718cb118e151dcd\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
      "Successfully built fire\n",
      "Installing collected packages: sentencepiece, pytz, pydub, xxhash, websockets, urllib3, tzdata, typing-extensions, tqdm, tomlkit, termcolor, shtab, shellingham, semantic-version, scipy, safetensors, ruff, regex, python-multipart, pyarrow, protobuf, propcache, orjson, mdurl, kiwisolver, importlib-resources, h11, fsspec, frozenlist, fonttools, ffmpy, einops, docstring-parser, dill, cycler, contourpy, click, av, async-timeout, annotated-types, aiohappyeyeballs, aiofiles, uvicorn, requests, pydantic-core, pandas, multiprocess, multidict, matplotlib, markdown-it-py, httpcore, fire, anyio, aiosignal, yarl, tiktoken, starlette, rich, pydantic, huggingface-hub, httpx, tyro, typer, tokenizers, sse-starlette, gradio-client, fastapi, aiohttp, accelerate, transformers, gradio, peft, datasets, trl\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.13\n",
      "    Uninstalling urllib3-1.26.13:\n",
      "      Successfully uninstalled urllib3-1.26.13\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "Successfully installed accelerate-1.0.1 aiofiles-23.2.1 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 async-timeout-5.0.1 av-14.0.1 click-8.1.8 contourpy-1.3.1 cycler-0.12.1 datasets-3.1.0 dill-0.3.8 docstring-parser-0.16 einops-0.8.0 fastapi-0.115.6 ffmpy-0.5.0 fire-0.7.0 fonttools-4.55.3 frozenlist-1.5.0 fsspec-2024.9.0 gradio-4.44.1 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 huggingface-hub-0.27.1 importlib-resources-6.5.2 kiwisolver-1.4.8 markdown-it-py-3.0.0 matplotlib-3.10.0 mdurl-0.1.2 multidict-6.1.0 multiprocess-0.70.16 orjson-3.10.14 pandas-2.2.3 peft-0.12.0 propcache-0.2.1 protobuf-5.29.3 pyarrow-18.1.0 pydantic-2.10.5 pydantic-core-2.27.2 pydub-0.25.1 python-multipart-0.0.20 pytz-2024.2 regex-2024.11.6 requests-2.32.3 rich-13.9.4 ruff-0.9.1 safetensors-0.5.2 scipy-1.15.1 semantic-version-2.10.0 sentencepiece-0.2.0 shellingham-1.5.4 shtab-1.7.1 sse-starlette-2.2.1 starlette-0.41.3 termcolor-2.5.0 tiktoken-0.8.0 tokenizers-0.20.3 tomlkit-0.12.0 tqdm-4.67.1 transformers-4.46.1 trl-0.9.6 typer-0.15.1 typing-extensions-4.12.2 tyro-0.8.14 tzdata-2024.2 urllib3-2.3.0 uvicorn-0.34.0 websockets-12.0 xxhash-3.5.0 yarl-1.18.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting deepspeed==0.14.0\n",
      "  Downloading deepspeed-0.14.0.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting hjson (from deepspeed==0.14.0)\n",
      "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting ninja (from deepspeed==0.14.0)\n",
      "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.0) (5.9.6)\n",
      "Collecting py-cpuinfo (from deepspeed==0.14.0)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.0) (2.10.5)\n",
      "Collecting pynvml (from deepspeed==0.14.0)\n",
      "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.0) (2.1.0+cu118)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.0) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.0) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.0) (4.12.2)\n",
      "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml->deepspeed==0.14.0)\n",
      "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.0) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.0) (2024.9.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.0) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed==0.14.0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed==0.14.0) (1.3.0)\n",
      "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
      "Downloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.14.0-py3-none-any.whl size=1400397 sha256=0c9dc30c6432c11efc65df221d6513516870dbf5a021a73cf022d9a22823d0c3\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/96/24/bab20c3b4e2af15e195b339afaec373eca7072cf90620432e5\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: py-cpuinfo, nvidia-ml-py, hjson, pynvml, ninja, deepspeed\n",
      "Successfully installed deepspeed-0.14.0 hjson-3.1.0 ninja-1.11.1.3 nvidia-ml-py-12.560.30 py-cpuinfo-9.0.0 pynvml-12.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Obtaining file:///workspace/LLaMA-Factory\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<=4.46.1,>=4.41.2 in /usr/local/lib/python3.10/dist-packages (4.46.1)\n",
      "Requirement already satisfied: datasets<=3.1.0,>=2.16.0 in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
      "Requirement already satisfied: accelerate<=1.0.1,>=0.34.0 in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
      "Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
      "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.10/dist-packages (0.9.6)\n",
      "Requirement already satisfied: tokenizers<0.20.4,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
      "Requirement already satisfied: gradio<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (4.44.1)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.15.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (5.29.3)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.34.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.10.5)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.6)\n",
      "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (23.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (1.24.1)\n",
      "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (14.0.1)\n",
      "Requirement already satisfied: tyro<0.9.0 in /usr/local/lib/python3.10/dist-packages (0.8.14)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rouge-chinese\n",
      "  Downloading rouge_chinese-1.0.3-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=1.0.1,>=0.34.0) (5.9.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=1.0.1,>=0.34.0) (0.27.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate<=1.0.1,>=0.34.0) (0.5.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.1.0,>=2.16.0) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=3.1.0,>=2.16.0) (3.11.11)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (4.8.0)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (0.28.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (6.5.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (2.1.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (3.10.14)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (9.3.0)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (0.9.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0.0,>=4.0.0) (2.3.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio<5.0.0,>=4.0.0) (12.0)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.41.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.7.0) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.27.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1) (3.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.46.1,>=4.41.2) (2024.11.6)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro<0.9.0) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro<0.9.0) (13.9.4)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro<0.9.0) (1.7.1)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.5.0)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from rouge-chinese) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0) (1.1.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=3.1.0,>=2.16.0) (1.18.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0) (1.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.16.0) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro<0.9.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro<0.9.0) (2.16.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0) (1.5.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0) (0.1.2)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m156.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hChecking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: jieba, llamafactory\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=d7d2c771b11ec4bec57903f60e1d739b3d7c8585a613e9fe669cba614627f576\n",
      "  Stored in directory: /root/.cache/pip/wheels/c9/69/31/d56d90b22a1777b0b231e234b00302a55be255930f8bd92dcd\n",
      "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llamafactory: filename=llamafactory-0.9.2.dev0-0.editable-py3-none-any.whl size=23888 sha256=a0e979784d549fe438e8940f8b6809ab271cf7b6e82cad1699a7936d394b7291\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-97oly68m/wheels/6b/fb/2e/068b37b77399a386b5777cf8b247cb07a69197b4baef3732a2\n",
      "Successfully built jieba llamafactory\n",
      "Installing collected packages: jieba, rouge-chinese, joblib, nltk, llamafactory\n",
      "Successfully installed jieba-0.42.1 joblib-1.4.2 llamafactory-0.9.2.dev0 nltk-3.9.1 rouge-chinese-1.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install deepspeed==0.14.0\n",
    "!pip install -e \".[torch,metrics]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0160fe93-5195-40fc-ac3e-decac9eff8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]\n",
      "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1197 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]      \n",
      "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2517 kB]\n",
      "Get:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]    \n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [53.3 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1517 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2840 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3633 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3448 kB]\n",
      "Get:21 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [45.2 kB]\n",
      "Get:22 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1226 kB]\n",
      "Fetched 37.0 MB in 2s (15.4 MB/s)                           \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libgpm2 libsodium23 vim-common vim-runtime xxd\n",
      "Suggested packages:\n",
      "  gpm ctags vim-doc vim-scripts\n",
      "The following NEW packages will be installed:\n",
      "  libgpm2 libsodium23 vim vim-common vim-runtime xxd\n",
      "0 upgraded, 6 newly installed, 0 to remove and 122 not upgraded.\n",
      "Need to get 8876 kB of archives.\n",
      "After this operation, 38.8 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xxd amd64 2:8.2.3995-1ubuntu2.21 [52.3 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.21 [81.5 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgpm2 amd64 1.20.7-10build1 [15.3 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsodium23 amd64 1.0.18-1build2 [164 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.21 [6834 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.21 [1729 kB]\n",
      "Fetched 8876 kB in 1s (8763 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package xxd.\n",
      "(Reading database ... 20729 files and directories currently installed.)\n",
      "Preparing to unpack .../0-xxd_2%3a8.2.3995-1ubuntu2.21_amd64.deb ...\n",
      "Unpacking xxd (2:8.2.3995-1ubuntu2.21) ...\n",
      "Selecting previously unselected package vim-common.\n",
      "Preparing to unpack .../1-vim-common_2%3a8.2.3995-1ubuntu2.21_all.deb ...\n",
      "Unpacking vim-common (2:8.2.3995-1ubuntu2.21) ...\n",
      "Selecting previously unselected package libgpm2:amd64.\n",
      "Preparing to unpack .../2-libgpm2_1.20.7-10build1_amd64.deb ...\n",
      "Unpacking libgpm2:amd64 (1.20.7-10build1) ...\n",
      "Selecting previously unselected package libsodium23:amd64.\n",
      "Preparing to unpack .../3-libsodium23_1.0.18-1build2_amd64.deb ...\n",
      "Unpacking libsodium23:amd64 (1.0.18-1build2) ...\n",
      "Selecting previously unselected package vim-runtime.\n",
      "Preparing to unpack .../4-vim-runtime_2%3a8.2.3995-1ubuntu2.21_all.deb ...\n",
      "Adding 'diversion of /usr/share/vim/vim82/doc/help.txt to /usr/share/vim/vim82/doc/help.txt.vim-tiny by vim-runtime'\n",
      "Adding 'diversion of /usr/share/vim/vim82/doc/tags to /usr/share/vim/vim82/doc/tags.vim-tiny by vim-runtime'\n",
      "Unpacking vim-runtime (2:8.2.3995-1ubuntu2.21) ...\n",
      "Selecting previously unselected package vim.\n",
      "Preparing to unpack .../5-vim_2%3a8.2.3995-1ubuntu2.21_amd64.deb ...\n",
      "Unpacking vim (2:8.2.3995-1ubuntu2.21) ...\n",
      "Setting up libsodium23:amd64 (1.0.18-1build2) ...\n",
      "Setting up libgpm2:amd64 (1.20.7-10build1) ...\n",
      "Setting up xxd (2:8.2.3995-1ubuntu2.21) ...\n",
      "Setting up vim-common (2:8.2.3995-1ubuntu2.21) ...\n",
      "Setting up vim-runtime (2:8.2.3995-1ubuntu2.21) ...\n",
      "Setting up vim (2:8.2.3995-1ubuntu2.21) ...\n",
      "update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vim (vim) in auto mode\n",
      "update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vimdiff (vimdiff) in auto mode\n",
      "update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/rvim (rvim) in auto mode\n",
      "update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/rview (rview) in auto mode\n",
      "update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vi (vi) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/da/man1/vi.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group vi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/de/man1/vi.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group vi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/vi.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group vi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/it/man1/vi.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group vi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/ja/man1/vi.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group vi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/pl/man1/vi.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group vi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/ru/man1/vi.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group vi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/vi.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group vi) doesn't exist\n",
      "update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/view (view) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/da/man1/view.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group view) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/de/man1/view.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group view) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/view.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group view) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/it/man1/view.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group view) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/ja/man1/view.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group view) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/pl/man1/view.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group view) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/ru/man1/view.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group view) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/view.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group view) doesn't exist\n",
      "update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/ex (ex) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/da/man1/ex.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group ex) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/de/man1/ex.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group ex) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/ex.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group ex) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/it/man1/ex.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group ex) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/ja/man1/ex.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group ex) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/pl/man1/ex.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group ex) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/ru/man1/ex.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group ex) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/ex.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group ex) doesn't exist\n",
      "update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/editor (editor) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/da/man1/editor.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group editor) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/de/man1/editor.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group editor) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/editor.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group editor) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/it/man1/editor.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group editor) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/ja/man1/editor.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group editor) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/pl/man1/editor.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group editor) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/ru/man1/editor.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group editor) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/editor.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group editor) doesn't exist\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install vim -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f79adaab-dc77-42f2-ab6e-db9b6656b8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "The token `llamaf` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `llamaf`\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93c5a704-e89f-4a7f-a84d-536812a0f4d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-02 13:35:16,785] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[INFO|2025-01-02 13:35:19] llamafactory.cli:157 >> Initializing distributed tasks at: 127.0.0.1:26342\n",
      "[2025-01-02 13:35:20,312] torch.distributed.run: [WARNING] \n",
      "[2025-01-02 13:35:20,312] torch.distributed.run: [WARNING] *****************************************\n",
      "[2025-01-02 13:35:20,312] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "[2025-01-02 13:35:20,312] torch.distributed.run: [WARNING] *****************************************\n",
      "[2025-01-02 13:35:24,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-01-02 13:35:24,420] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-01-02 13:35:24,427] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[INFO|2025-01-02 13:35:25] llamafactory.hparams.parser:359 >> Process rank: 2, device: cuda:2, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16\n",
      "[INFO|2025-01-02 13:35:25] llamafactory.hparams.parser:359 >> Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16\n",
      "[WARNING|2025-01-02 13:35:25] llamafactory.hparams.parser:162 >> `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
      "[INFO|2025-01-02 13:35:25] llamafactory.hparams.parser:359 >> Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16\n",
      "[INFO|configuration_utils.py:679] 2025-01-02 13:35:25,853 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-02 13:35:25,855 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-02 13:35:25,976 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-02 13:35:25,976 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-02 13:35:25,976 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-02 13:35:25,977 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-02 13:35:25,977 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2475] 2025-01-02 13:35:26,320 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:679] 2025-01-02 13:35:26,961 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-02 13:35:26,962 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-02 13:35:27,084 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-02 13:35:27,084 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-02 13:35:27,084 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-02 13:35:27,084 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-02 13:35:27,084 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2475] 2025-01-02 13:35:27,403 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|2025-01-02 13:35:27] llamafactory.data.template:157 >> Replace eos token: <|eot_id|>\n",
      "[INFO|2025-01-02 13:35:27] llamafactory.data.template:157 >> Add pad token: <|eot_id|>\n",
      "[INFO|2025-01-02 13:35:27] llamafactory.data.loader:157 >> Loading dataset company_extract.json...\n",
      "Converting format of dataset (num_proc=16): 100%|█| 2000/2000 [00:00<00:00, 1007\n",
      "Running tokenizer on dataset (num_proc=16): 100%|█| 2000/2000 [00:02<00:00, 804.\n",
      "training example:\n",
      "input_ids:\n",
      "[128000, 128006, 9125, 128007, 271, 65895, 83628, 34804, 127798, 126546, 107364, 16969, 102783, 245, 103850, 229, 80052, 13, 4815, 7860, 67890, 30426, 126840, 7860, 720, 16, 13, 56773, 125441, 43449, 19954, 74618, 81673, 114500, 127798, 126546, 107364, 34609, 51402, 720, 17, 13, 127798, 126546, 107364, 18359, 24140, 47782, 115300, 11, 122292, 56069, 13094, 168, 235, 105, 84734, 18918, 62226, 101360, 11, 105813, 21028, 17835, 111964, 16582, 113348, 45618, 49085, 88525, 96677, 51402, 13, 720, 18, 13, 62226, 34804, 64857, 30446, 30426, 56069, 13094, 168, 235, 105, 21028, 84734, 106612, 87472, 17835, 53017, 16582, 119978, 627, 19, 13, 111068, 25941, 167, 51462, 25, 13094, 56773, 32179, 22035, 33390, 127798, 29102, 54289, 25, 106788, 19954, 56069, 13094, 168, 235, 105, 84734, 106612, 87472, 17835, 114839, 92245, 13, 128009, 128006, 882, 128007, 271, 121096, 167, 51462, 25, 57519, 21121, 57390, 100508, 77437, 36609, 25941, 106634, 27796, 116425, 119398, 121820, 102525, 16969, 121883, 105411, 17835, 41381, 102766, 3100, 654, 444, 58453, 43405, 12604, 6266, 56154, 81673, 220, 1272, 108609, 55421, 111850, 101555, 21028, 364, 7939, 51, 59436, 117467, 67945, 27797, 103123, 33177, 20565, 25941, 86422, 22035, 21121, 8, 103123, 33177, 101696, 88708, 29833, 71023, 120287, 19954, 102597, 97096, 55430, 27796, 18918, 29833, 104366, 101528, 35495, 220, 508, 33177, 116283, 48555, 104828, 13, 13094, 43144, 97096, 55430, 27796, 102772, 49508, 64189, 13447, 71682, 125554, 102160, 101090, 118859, 101314, 119864, 9827, 45, 7767, 4444, 20218, 73879, 5165, 15895, 8351, 8, 81673, 21028, 126902, 101015, 103168, 49085, 110097, 33308, 120, 91786, 13, 121820, 102525, 16969, 104350, 34983, 103551, 9827, 45, 7767, 19954, 220, 19, 100392, 63375, 220, 23, 73653, 123590, 328, 26460, 18918, 67890, 102130, 100994, 102662, 48936, 126088, 101568, 13, 82233, 17835, 41381, 102766, 117396, 121883, 21028, 96102, 100711, 11135, 278, 1764, 8, 49706, 116594, 21028, 65677, 127702, 17835, 107285, 17835, 110452, 36609, 25941, 86422, 22035, 21121, 116604, 127302, 13447, 13, 121820, 102525, 21028, 328, 26460, 18918, 507, 8561, 7, 38187, 93917, 101096, 26799, 111426, 77535, 86157, 8, 75908, 77437, 43139, 100994, 102662, 107094, 54059, 120138, 72043, 58189, 120257, 109916, 19954, 116604, 101360, 91786, 13, 121066, 34983, 121820, 102525, 57575, 220, 1627, 108609, 55421, 111850, 101555, 328, 26460, 112785, 18359, 100994, 102662, 24486, 82818, 91786, 13, 106634, 102525, 116680, 112953, 330, 35859, 80979, 116281, 21121, 124991, 107120, 110670, 119262, 32428, 74177, 33177, 5, 20565, 25941, 119262, 57575, 55216, 109074, 116534, 56154, 106001, 102888, 111373, 20565, 121856, 22035, 104448, 67890, 102130, 104182, 100994, 102662, 101438, 104690, 13094, 122862, 101360, 91786, 1, 35495, 108537, 13, 117012, 110155, 123102, 119262, 57575, 112785, 33931, 67119, 19954, 102597, 101834, 24140, 111490, 127507, 107094, 101760, 35495, 58935, 102252, 123102, 102293, 71023, 103686, 67945, 19954, 102597, 106915, 103655, 18359, 67236, 71682, 127505, 13, 16582, 104303, 107837, 121820, 102525, 116865, 16969, 330, 13094, 43144, 120287, 18359, 110155, 108100, 109817, 59777, 113037, 59134, 104303, 13094, 74177, 33177, 14260, 20565, 25941, 119262, 101838, 101314, 106304, 103686, 106687, 121856, 107054, 107387, 74959, 101528, 1, 35495, 116283, 35859, 104828, 13, 117819, 330, 104156, 104152, 112780, 104323, 107489, 13094, 81673, 14031, 1341, 19954, 64857, 49085, 50643, 46204, 117, 112785, 79225, 102662, 18359, 46810, 62398, 102326, 116090, 27797, 100514, 246, 104236, 105880, 97096, 102937, 116429, 112780, 64857, 49085, 50643, 119262, 102464, 71023, 13094, 84415, 6026, 121, 21121, 103123, 101015, 1, 51440, 101203, 330, 21, 125085, 63375, 126253, 103684, 116090, 18918, 96677, 100981, 29102, 101360, 104414, 102079, 104182, 220, 112785, 79225, 102662, 19954, 74618, 102546, 29833, 123644, 82273, 126712, 50467, 48936, 72208, 1, 110917, 108537, 13, 24486, 104790, 119929, 121820, 102525, 20565, 112780, 104323, 107489, 13094, 11, 14031, 1341, 19954, 97096, 102937, 24486, 100514, 246, 104236, 104210, 112780, 104323, 107489, 111721, 64432, 101314, 101360, 65621, 220, 717, 123590, 64857, 49085, 50643, 46204, 117, 54780, 112780, 125554, 56069, 94772, 124365, 107022, 50643, 32428, 14031, 1341, 46204, 117, 19954, 115426, 112931, 13, 121820, 102525, 21028, 36609, 25941, 66406, 108728, 16969, 125554, 220, 21, 125085, 63375, 21028, 116090, 111323, 220, 101834, 101151, 104182, 103521, 102546, 72043, 32428, 104323, 107489, 13094, 81673, 14031, 1341, 64857, 49085, 50643, 46204, 117, 19954, 115426, 113191, 126088, 101568, 13, 83628, 101607, 66406, 62398, 66406, 9019, 115, 124158, 126887, 9063, 31, 71, 92916, 2234, 916, 220, 128009, 128006, 78191, 128007, 127702, 29102, 54289, 551, 2570, 106634, 102525, 518, 364, 82233, 17835, 41381, 102766, 518, 364, 1846, 45, 7767, 663, 128009]\n",
      "inputs:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "당신은 회사명을 찾는 챗봇입니다. \n",
      "\n",
      " ## 지시 사항 ## \n",
      "1. 주어진 입력에 나와있는 회사명을 찾으세요 \n",
      "2. 회사명을 찾을수 없다면, 빈 파이썬 리스트를 출력하고, 임의로 답변하려고 시도하지 마세요. \n",
      "3. 출력은 반드시 파이썬의 리스트 형태로 생성하십시오.\n",
      "4. 뉴스데이터:이 주어지면 회사리스트: 다음에 파이썬 리스트 형태로 작성하세요.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "뉴스데이터: 전기화학식 가스센서 전문기업 센코는 영국 크로우콘(Crowcon Detection Instrument Ltd.)사와 40억원 규모의 'SGT'(휴대용 단일가스 검지기) 단일품목 수출 계약에 대한 발주서를 수령했다고 20일 밝 혔다.이번 발주서에는 아부다비 최대 국영 석유 기업 ADNOC(Abu Dhabi National Oil Company)와의 신규계약도 포함돼 있다. 센코는 올해부터 ADNOC에 4년간 8만개의 SGT를 지속 공급할 예정이다.크로우콘사는 영국의 할마(Halma)그룹의 자회사로 글로벌 가스 검지기 판매업체다. 센코의 SGT를 ODM(제조업자 개발생산) 방식으로 공급받아 주요 중동지역 국가에 판매하고 있다. 지난해 센코에서 26억원 규모 SGT 제품을 공급한 바 있다.센코 관계자는 \"현재 안전기기의 가장 큰 시장인 오일&가스 시장에서 기존 고객사들의 재 구매가 이어지면서 지속적으로 공급물량이 증가하고 있다\"고 말했다. 이를 통해 해외 시장에서 제품성능에 대한 우수성을 인정받았고 추후 해외 매출 확대에 대한 자신감을 내비쳤다.하승철 센코 대표는 \"이번 계약을 통해 브랜드 인지도 상승이 오일·가스 시장점유율 확대로 이어지는 것을 확인했다\"고 밝혔다.이어 \"최근 중국 화웨이와 SMIC에 반도체 팹 제품공급을 위 한 실 평가용 샘플들을 발송하면서 중국 반도체 시장 진출이 초읽기 단계\"라며 \"6개월간 성공적인 평가를 마무리하고 본격적으로  제품공급에 나설 수 있도록 최선을 다할 것\"이라고 말했다.한편 최근 센코가 중국 화웨이, SMIC에 발송한 샘플들은 중국 화웨이가 보유하고 있는 12개의 반도체 팹과 중국 최대 파운드리 업체인 SMIC 팹에 설치된다. 센코의 가스경보기는 최대 6개월간의 평가 이후  우선적으로 건설 중인 화웨이와 SMIC 반도체 팹에 설치될 예정이다.신민경 한경닷컴 기자 radio@hankyung.com <|eot_id|><|start_header_id|>assistant<|end_header_id|>회사리스트 : ['센코', '크로우콘', 'ADNOC']<|eot_id|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 127702, 29102, 54289, 551, 2570, 106634, 102525, 518, 364, 82233, 17835, 41381, 102766, 518, 364, 1846, 45, 7767, 663, 128009]\n",
      "labels:\n",
      "회사리스트 : ['센코', '크로우콘', 'ADNOC']<|eot_id|>\n",
      "[INFO|configuration_utils.py:679] 2025-01-02 13:35:32,153 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-02 13:35:32,155 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3937] 2025-01-02 13:35:32,216 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1670] 2025-01-02 13:35:32,218 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1096] 2025-01-02 13:35:32,220 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.69it/s]\n",
      "[INFO|modeling_utils.py:4800] 2025-01-02 13:35:33,446 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4808] 2025-01-02 13:35:33,447 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Llama-3.2-3B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.73it/s]\n",
      "[INFO|configuration_utils.py:1051] 2025-01-02 13:35:33,608 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/generation_config.json\n",
      "[INFO|configuration_utils.py:1096] 2025-01-02 13:35:33,609 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n",
      "[INFO|2025-01-02 13:35:33] llamafactory.model.model_utils.checkpointing:157 >> Gradient checkpointing enabled.\n",
      "[INFO|2025-01-02 13:35:33] llamafactory.model.model_utils.attention:157 >> Using vanilla attention implementation.\n",
      "[INFO|2025-01-02 13:35:33] llamafactory.model.adapter:157 >> Upcasting trainable params to float32.\n",
      "[INFO|2025-01-02 13:35:33] llamafactory.model.adapter:157 >> Fine-tuning method: LoRA\n",
      "[INFO|2025-01-02 13:35:33] llamafactory.model.model_utils.misc:157 >> Found linear modules: up_proj,down_proj,o_proj,gate_proj,v_proj,q_proj,k_proj\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.59it/s]\n",
      "[INFO|2025-01-02 13:35:33] llamafactory.model.loader:157 >> trainable params: 12,156,928 || all params: 3,224,906,752 || trainable%: 0.3770\n",
      "[INFO|trainer.py:698] 2025-01-02 13:35:33,860 >> Using auto half precision backend\n",
      "[WARNING|2025-01-02 13:35:33] llamafactory.train.callbacks:168 >> Previous trainer log in this folder will be deleted.\n",
      "[INFO|trainer.py:2313] 2025-01-02 13:35:34,343 >> ***** Running training *****\n",
      "[INFO|trainer.py:2314] 2025-01-02 13:35:34,343 >>   Num examples = 1,800\n",
      "[INFO|trainer.py:2315] 2025-01-02 13:35:34,343 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:2316] 2025-01-02 13:35:34,343 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2319] 2025-01-02 13:35:34,343 >>   Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "[INFO|trainer.py:2320] 2025-01-02 13:35:34,344 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2321] 2025-01-02 13:35:34,344 >>   Total optimization steps = 370\n",
      "[INFO|trainer.py:2322] 2025-01-02 13:35:34,346 >>   Number of trainable parameters = 12,156,928\n",
      "{'loss': 2.8334, 'grad_norm': 6.420775890350342, 'learning_rate': 2.702702702702703e-05, 'epoch': 0.27}\n",
      "{'loss': 1.488, 'grad_norm': 2.5561649799346924, 'learning_rate': 5.405405405405406e-05, 'epoch': 0.53}\n",
      "{'loss': 0.3975, 'grad_norm': 0.8492634892463684, 'learning_rate': 8.108108108108109e-05, 'epoch': 0.8}\n",
      "{'loss': 0.2856, 'grad_norm': 0.7377635836601257, 'learning_rate': 9.99799753559161e-05, 'epoch': 1.07}\n",
      "{'loss': 0.2025, 'grad_norm': 1.0493342876434326, 'learning_rate': 9.962442770775675e-05, 'epoch': 1.33}\n",
      "{'loss': 0.1858, 'grad_norm': 0.7458379864692688, 'learning_rate': 9.882752851759248e-05, 'epoch': 1.6}\n",
      "{'loss': 0.1756, 'grad_norm': 0.8368340134620667, 'learning_rate': 9.759636527645633e-05, 'epoch': 1.87}\n",
      "{'loss': 0.1639, 'grad_norm': 0.5459277033805847, 'learning_rate': 9.594188774880982e-05, 'epoch': 2.13}\n",
      "{'loss': 0.1223, 'grad_norm': 0.6222749948501587, 'learning_rate': 9.387881058712888e-05, 'epoch': 2.4}\n",
      "{'loss': 0.136, 'grad_norm': 1.081336259841919, 'learning_rate': 9.142548246219212e-05, 'epoch': 2.67}\n",
      " 27%|███████████                              | 100/370 [08:12<21:25,  4.76s/it][INFO|trainer.py:3801] 2025-01-02 13:43:47,173 >> Saving model checkpoint to checkpoint/checkpoint-100\n",
      "[INFO|configuration_utils.py:679] 2025-01-02 13:43:47,510 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-02 13:43:47,511 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2025-01-02 13:43:47,761 >> tokenizer config file saved in checkpoint/checkpoint-100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2025-01-02 13:43:47,764 >> Special tokens file saved in checkpoint/checkpoint-100/special_tokens_map.json\n",
      "{'loss': 0.1149, 'grad_norm': 0.6830071210861206, 'learning_rate': 8.860372287300431e-05, 'epoch': 2.93}\n",
      "{'loss': 0.11, 'grad_norm': 0.5803897976875305, 'learning_rate': 8.543862808774192e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0852, 'grad_norm': 0.5227697491645813, 'learning_rate': 8.195834794164925e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0914, 'grad_norm': 0.7082261443138123, 'learning_rate': 7.81938354770089e-05, 'epoch': 3.73}\n",
      "{'loss': 0.0969, 'grad_norm': 0.91753751039505, 'learning_rate': 7.417857165184723e-05, 'epoch': 4.0}\n",
      "{'loss': 0.0655, 'grad_norm': 0.4577527344226837, 'learning_rate': 6.994826756577082e-05, 'epoch': 4.27}\n",
      "{'loss': 0.0637, 'grad_norm': 0.6807425022125244, 'learning_rate': 6.554054685128856e-05, 'epoch': 4.53}\n",
      "{'loss': 0.0715, 'grad_norm': 0.7627411484718323, 'learning_rate': 6.099461105537889e-05, 'epoch': 4.8}\n",
      "{'loss': 0.0778, 'grad_norm': 0.5515148043632507, 'learning_rate': 5.6350890987343944e-05, 'epoch': 5.07}\n",
      "{'loss': 0.0492, 'grad_norm': 0.6589899063110352, 'learning_rate': 5.1650687133805674e-05, 'epoch': 5.33}\n",
      " 54%|██████████████████████▏                  | 200/370 [16:28<13:37,  4.81s/it][INFO|trainer.py:3801] 2025-01-02 13:52:02,393 >> Saving model checkpoint to checkpoint/checkpoint-200\n",
      "[INFO|configuration_utils.py:679] 2025-01-02 13:52:02,868 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-02 13:52:02,869 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2025-01-02 13:52:03,059 >> tokenizer config file saved in checkpoint/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2025-01-02 13:52:03,062 >> Special tokens file saved in checkpoint/checkpoint-200/special_tokens_map.json\n",
      "{'loss': 0.0515, 'grad_norm': 0.5386145710945129, 'learning_rate': 4.69358023389342e-05, 'epoch': 5.6}\n",
      "{'loss': 0.0527, 'grad_norm': 0.5849591493606567, 'learning_rate': 4.224817001679011e-05, 'epoch': 5.87}\n",
      "{'loss': 0.0449, 'grad_norm': 0.42617177963256836, 'learning_rate': 3.762948120239988e-05, 'epoch': 6.13}\n",
      "{'loss': 0.0391, 'grad_norm': 0.43042629957199097, 'learning_rate': 3.312081375851038e-05, 'epoch': 6.4}\n",
      "{'loss': 0.0431, 'grad_norm': 0.6739886403083801, 'learning_rate': 2.876226703579761e-05, 'epoch': 6.67}\n",
      "{'loss': 0.0417, 'grad_norm': 0.5618463754653931, 'learning_rate': 2.459260523580154e-05, 'epoch': 6.93}\n",
      "{'loss': 0.0349, 'grad_norm': 0.5230619311332703, 'learning_rate': 2.0648912648459074e-05, 'epoch': 7.2}\n",
      "{'loss': 0.0354, 'grad_norm': 0.500717043876648, 'learning_rate': 1.6966263830495936e-05, 'epoch': 7.47}\n",
      "{'loss': 0.0322, 'grad_norm': 0.6174072623252869, 'learning_rate': 1.3577411658056966e-05, 'epoch': 7.73}\n",
      "{'loss': 0.0331, 'grad_norm': 0.7146167755126953, 'learning_rate': 1.0512496027983714e-05, 'epoch': 8.0}\n",
      " 81%|█████████████████████████████████▏       | 300/370 [24:47<05:32,  4.76s/it][INFO|trainer.py:3801] 2025-01-02 14:00:22,028 >> Saving model checkpoint to checkpoint/checkpoint-300\n",
      "[INFO|configuration_utils.py:679] 2025-01-02 14:00:22,421 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-02 14:00:22,423 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2025-01-02 14:00:22,651 >> tokenizer config file saved in checkpoint/checkpoint-300/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2025-01-02 14:00:22,654 >> Special tokens file saved in checkpoint/checkpoint-300/special_tokens_map.json\n",
      "{'loss': 0.0289, 'grad_norm': 0.5287202596664429, 'learning_rate': 7.798775798502483e-06, 'epoch': 8.27}\n",
      "{'loss': 0.0278, 'grad_norm': 0.593993067741394, 'learning_rate': 5.460386353398583e-06, 'epoch': 8.53}\n",
      "{'loss': 0.0269, 'grad_norm': 0.42566102743148804, 'learning_rate': 3.51812494586114e-06, 'epoch': 8.8}\n",
      "{'loss': 0.0278, 'grad_norm': 0.5973324775695801, 'learning_rate': 1.9892657311155248e-06, 'epoch': 9.07}\n",
      "{'loss': 0.0241, 'grad_norm': 0.5629917979240417, 'learning_rate': 8.874061329125938e-07, 'epoch': 9.33}\n",
      "{'loss': 0.0242, 'grad_norm': 0.39818212389945984, 'learning_rate': 2.223459102662695e-07, 'epoch': 9.6}\n",
      "{'loss': 0.0272, 'grad_norm': 0.3949759006500244, 'learning_rate': 0.0, 'epoch': 9.87}\n",
      "100%|█████████████████████████████████████████| 370/370 [30:34<00:00,  5.08s/it][INFO|trainer.py:3801] 2025-01-02 14:06:08,424 >> Saving model checkpoint to checkpoint/checkpoint-370\n",
      "[INFO|configuration_utils.py:679] 2025-01-02 14:06:08,675 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-02 14:06:08,675 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2025-01-02 14:06:08,941 >> tokenizer config file saved in checkpoint/checkpoint-370/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2025-01-02 14:06:08,945 >> Special tokens file saved in checkpoint/checkpoint-370/special_tokens_map.json\n",
      "[INFO|trainer.py:2584] 2025-01-02 14:06:09,457 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 1835.1111, 'train_samples_per_second': 9.809, 'train_steps_per_second': 0.202, 'train_loss': 0.20033883996106483, 'epoch': 9.87}\n",
      "100%|█████████████████████████████████████████| 370/370 [30:35<00:00,  4.96s/it]\n",
      "[INFO|trainer.py:3801] 2025-01-02 14:06:09,463 >> Saving model checkpoint to checkpoint\n",
      "[INFO|configuration_utils.py:679] 2025-01-02 14:06:09,689 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-02 14:06:09,691 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2025-01-02 14:06:09,871 >> tokenizer config file saved in checkpoint/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2025-01-02 14:06:09,875 >> Special tokens file saved in checkpoint/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =      9.8667\n",
      "  total_flos               = 318685496GF\n",
      "  train_loss               =      0.2003\n",
      "  train_runtime            =  0:30:35.11\n",
      "  train_samples_per_second =       9.809\n",
      "  train_steps_per_second   =       0.202\n",
      "Figure saved at: checkpoint/training_loss.png\n",
      "[WARNING|2025-01-02 14:06:10] llamafactory.extras.ploting:162 >> No metric eval_loss to plot.\n",
      "[WARNING|2025-01-02 14:06:10] llamafactory.extras.ploting:162 >> No metric eval_accuracy to plot.\n",
      "[INFO|trainer.py:4117] 2025-01-02 14:06:10,184 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4119] 2025-01-02 14:06:10,184 >>   Num examples = 200\n",
      "[INFO|trainer.py:4122] 2025-01-02 14:06:10,184 >>   Batch size = 1\n",
      "100%|███████████████████████████████████████████| 67/67 [00:06<00:00, 10.58it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =     9.8667\n",
      "  eval_loss               =     0.2197\n",
      "  eval_runtime            = 0:00:06.40\n",
      "  eval_samples_per_second =      31.25\n",
      "  eval_steps_per_second   =     10.469\n",
      "[INFO|modelcard.py:449] 2025-01-02 14:06:16,596 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli train examples/train_lora/llama3_lora_compext.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c34c525-54a3-4935-8492-7172035f5b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.15s/it]\n",
      "Loading PEFT: ./checkpoint/checkpoint-300\n",
      "Running merge_and_unload\n",
      "[2025-01-02 14:10:47,256] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Model saved to ./output_dir\n"
     ]
    }
   ],
   "source": [
    "!python merge.py \\\n",
    "    --base_model_name_or_path meta-llama/Llama-3.2-3B-Instruct \\\n",
    "    --peft_model_path ./checkpoint/checkpoint-300 \\\n",
    "    --output_dir ./output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b091a110-5359-4fa2-aa68-298e74ddccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'LLaMA-Factory'\n",
      "/workspace/LLaMA-Factory\n"
     ]
    }
   ],
   "source": [
    "%cd LLaMA-Factory\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0146c5-1b98-411c-99a7-6caee5a3ba97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
